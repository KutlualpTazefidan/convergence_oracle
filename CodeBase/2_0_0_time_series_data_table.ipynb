{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future forecasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/7: Loading the dataset ...\n"
     ]
    }
   ],
   "source": [
    "## PULL Functions from custom functions\n",
    "from custom_functions import bertopic_addons as cfc\n",
    "\n",
    "## you will need to change the name below\n",
    "currenttable = 'topified_vectorized_Science1900_2023'\n",
    "aws_dfs = cfc.pull_aws_sql_database(currenttable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build in functionality for time frame no.of.months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paperId', 'externalIds', 'publicationVenue', 'title', 'abstract',\n",
       "       'year', 'referenceCount', 'citationCount', 'influentialCitationCount',\n",
       "       'fieldsOfStudy', 's2FieldsOfStudy', 'publicationTypes',\n",
       "       'publicationDate', 'title_abstract', 'topic_code', 'topic_list',\n",
       "       'x_vector', 'y_vector', 'z_vector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_dfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "moving_average_years = 1\n",
    "dataframe = aws_dfs\n",
    "dataframe['count'] = 1\n",
    "# Group by \"Topic\" and \"Timestamp\" and aggregate \"Frequency\"\n",
    "## metric can be 'count', 'citationCount', 'influentialCitationCount'\n",
    "type_of_metric = 'citationCount'\n",
    "timeframe = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53833, 20)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws1_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46284, 20)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws1_dfs[aws1_dfs['publicationDate'] != 'None'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can change this to all topics \n",
    "aws1_dfs= dataframe\n",
    "aws1_dfs['topic_code'] = pd.to_numeric(aws1_dfs['topic_code'], downcast='integer')\n",
    "aws1_dfs[type_of_metric] = pd.to_numeric(aws1_dfs[type_of_metric], downcast='integer')\n",
    "aws1_dfs = aws1_dfs[aws1_dfs['publicationDate'] != 'None']\n",
    "aws1_dfs['publicationDate'] = pd.to_datetime(aws1_dfs['publicationDate'], format='%Y-%m-%d')\n",
    "aws1_dfs['date'] = aws1_dfs['publicationDate'].dt.to_period(timeframe)\n",
    "aws1_dfs['date']=aws1_dfs['date'].astype(str)\n",
    "aws1_dfs['date']=pd.to_datetime(aws1_dfs['date'])\n",
    "# ==== LEGACY NO NEED :)) aws1_dfs= aws1_dfs[aws1_dfs['topic_code']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bertopic_data_into_future(dataframe, topic_number, future_years, moving_average, type_of_metric, timeframe):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### ============================ CLEANING UP DATAFRAME \n",
    "    ## number of years into the future you can forecast\n",
    "    if timeframe == 'M':\n",
    "        n = future_years*12\n",
    "        moving_average = moving_average*12\n",
    "    else: \n",
    "        n = future_years\n",
    "        \n",
    "    ## you can change this to all topics \n",
    "    aws1_dfs= dataframe\n",
    "    aws1_dfs['topic_code'] = pd.to_numeric(aws1_dfs['topic_code'], downcast='integer')\n",
    "    aws1_dfs[type_of_metric] = pd.to_numeric(aws1_dfs[type_of_metric], downcast='integer')\n",
    "    aws1_dfs = aws1_dfs[aws1_dfs['publicationDate'] != 'None'].reset_index()\n",
    "    aws1_dfs['publicationDate'] = pd.to_datetime(aws1_dfs['publicationDate'], format='%Y-%m-%d')\n",
    "    aws1_dfs['date'] = aws1_dfs['publicationDate'].dt.to_period(timeframe)\n",
    "    aws1_dfs['date']=aws1_dfs['date'].astype(str)\n",
    "    aws1_dfs['date']=pd.to_datetime(aws1_dfs['date'])\n",
    "    # ==== LEGACY NO NEED :)) aws1_dfs= aws1_dfs[aws1_dfs['topic_code']!=-1]\n",
    "\n",
    "    ## code to change the date time, for the moment use year\n",
    "    grouped_df = aws1_dfs.groupby(['topic_code', 'date'])[type_of_metric].sum().reset_index()\n",
    "\n",
    "    pivot_df = grouped_df.pivot(index='date', columns='topic_code', values=type_of_metric)\n",
    "\n",
    "    pivot_df.fillna(0, inplace=True)\n",
    "    pivot_df = pivot_df.reset_index()\n",
    "        \n",
    "    # Define the target column (Topic you want to forecast)\n",
    "    target_topic = topic_number  # Change this to the Topic you want to forecast\n",
    "        \n",
    "    # convert target topic to a moving average\n",
    "    ## now predicting the moving average\n",
    "    pivot_df[target_topic] = pivot_df[target_topic].rolling(moving_average_years).mean()\n",
    "\n",
    "\n",
    "    # Dropping last n rows using drop\n",
    "    target_column = pivot_df[target_topic]\n",
    "\n",
    "    # forget about the lost values\n",
    "    ## dropped the oldest columns\n",
    "    target_column.drop(target_column.head(n).index, inplace = True)\n",
    "\n",
    "    ## pivot_df['year'] + pd.offsets.DateOffset(years=5)\n",
    "    untarget_columns = pivot_df.drop(target_topic, axis=1)\n",
    "\n",
    "    ## keep this for later -- these are your forecasting columns \n",
    "    X_forecasting_data = untarget_columns.tail(n)\n",
    "    X_forecasting_years = untarget_columns['date'].tail(n) + pd.offsets.DateOffset(years=future_years)\n",
    "    X_forecasting_data['date'] = X_forecasting_years\n",
    "    X_forecasting = X_forecasting_data.drop(columns=['date'])\n",
    "\n",
    "    ##  drop the columns you keep for forecasting\n",
    "    untarget_columns.drop(target_column.tail(n).index, inplace = True)\n",
    "\n",
    "    df = pd.concat([untarget_columns, target_column.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    ## shift the prediction of each year\n",
    "    df['date'] = df['date'] + pd.offsets.DateOffset(years=future_years)\n",
    "\n",
    "    pivot_df = df    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ================== TEST TRAIN SPLIT \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Separating the training set and testing set\n",
    "    train_data=pivot_df[pivot_df['date'].dt.year<2011].reset_index(drop = True)\n",
    "    test_data=pivot_df[pivot_df['date'].dt.year>2010].reset_index(drop = True)\n",
    "\n",
    "    # Prepare the training and testing data\n",
    "    X_train = train_data.drop(target_topic, axis=1)\n",
    "    X_test = test_data.drop(target_topic, axis=1)\n",
    "\n",
    "    # Shift the target column to align with next year's frequency\n",
    "    y_train = train_data[target_topic].shift(-1).dropna()\n",
    "    y_test = test_data[target_topic].shift(-1).dropna()\n",
    "\n",
    "    # Exclude the 'YearMonth' column from the training and testing data\n",
    "    X_train = train_data.drop(columns=['date', target_topic]).iloc[:-1]\n",
    "    X_test = test_data.drop(columns=['date', target_topic]).iloc[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ======================= MODEL \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Create an XGBoost regressor\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_forecasting = model.predict(X_forecasting)\n",
    "\n",
    "    # Create a DataFrame with YearMonth and the predicted values\n",
    "    y_pred_df = pd.DataFrame({'date': test_data['date'].iloc[:-1], 'Predicted': y_pred})\n",
    "    y_fore_df = pd.DataFrame({'date': X_forecasting_years, 'Forecasted': y_forecasting})\n",
    "\n",
    "    # Merge the predicted DataFrame with the original test_data DataFrame\n",
    "    merged_data = pd.merge(y_pred_df, test_data, on='date')\n",
    "    merged_forecasted_data = pd.merge(y_fore_df, X_forecasting_data, on='date')\n",
    "\n",
    "    #print(merged_forecasted_data)\n",
    "    # Calculate the root mean squared error (RMSE)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    #print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## =============================   BUILDING DATA TABLE \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_actual_test_df = test_data[['date',target_topic]]\n",
    "    y_actual_train_df = train_data[['date',target_topic]]\n",
    "    y_fore_df =y_fore_df.rename(columns={'Forecasted': target_topic})\n",
    "    y_pred_df =y_pred_df.rename(columns={'Predicted': target_topic})\n",
    "\n",
    "    y_actual_test_df['value'] = 'Actual_Test'\n",
    "    y_actual_train_df['value'] = 'Actual_Train'\n",
    "    y_fore_df['value'] = 'Forecasted'\n",
    "    y_pred_df['value'] = 'Predicted_Test'\n",
    "\n",
    "    final_data = pd.concat([y_actual_test_df,y_actual_train_df,y_fore_df,y_pred_df], axis=0)\n",
    "    final_data =final_data.rename(columns={target_topic: 'quantity'})\n",
    "    final_data['topic_code'] = target_topic\n",
    "    final_data['RMSE'] = rmse\n",
    "    final_data['metric'] = type_of_metric\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"# Plot the predicted vs. actual values along with y_train\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(merged_data['year'], merged_data['Predicted'], label='Predicted', marker='x')\n",
    "    plt.plot(merged_data['year'], merged_data[target_topic], label='Actual', marker='o')\n",
    "    plt.plot(train_data['year'].iloc[:-1], y_train, label='Train', linestyle='--', color='gray')\n",
    "    plt.plot(merged_forecasted_data['year'], merged_forecasted_data['Forecasted'], label='Forecasted', marker='+')\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(type_of_metric)\n",
    "    plt.title(f'Topic {target_topic} Citation Forecast (RMSE: {rmse:.2f})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Feature importance plot (optional)\n",
    "    plot_importance(model)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    return final_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an ordered list of topic codes \n",
    "topic_code_list = list(pd.Series(dataframe['topic_code'].sort_values()).unique())\n",
    "\n",
    "## create a dataframe to concat later \n",
    "growing_df = pd.DataFrame()\n",
    "\n",
    "## for loop through the topic code list \n",
    "for j in ['count', 'citationCount', 'influentialCitationCount']:\n",
    "    for i in topic_code_list:\n",
    "        current_df = plot_bertopic_data_into_future(dataframe, i, 5, 4, j, timeframe)\n",
    "        growing_df = pd.concat([current_df, growing_df]) \n",
    "    \n",
    "## reset the index and drop the inxiex column \n",
    "growing_df = growing_df.reset_index().drop('index',axis=1)\n",
    "\n",
    "## match the topic code to the topic description \n",
    "topic_codes = dataframe[['topic_code','topic_list']].drop_duplicates().reset_index().drop('index',axis=1)\n",
    "\n",
    "## merge the topics descriptions to the data set\n",
    "full_datase= growing_df.merge(topic_codes, on='topic_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_functions import bertopic_addons as cfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/7: Loading the dataset ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>value</th>\n",
       "      <th>topic_code</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>metric</th>\n",
       "      <th>topic_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>Actual_Test</td>\n",
       "      <td>117</td>\n",
       "      <td>26.053664</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "      <td>117_multiple sclerosis_sclerosis_multiple_axonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>Actual_Test</td>\n",
       "      <td>117</td>\n",
       "      <td>26.053664</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "      <td>117_multiple sclerosis_sclerosis_multiple_axonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Actual_Test</td>\n",
       "      <td>117</td>\n",
       "      <td>26.053664</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "      <td>117_multiple sclerosis_sclerosis_multiple_axonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Actual_Test</td>\n",
       "      <td>117</td>\n",
       "      <td>26.053664</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "      <td>117_multiple sclerosis_sclerosis_multiple_axonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Actual_Test</td>\n",
       "      <td>117</td>\n",
       "      <td>26.053664</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "      <td>117_multiple sclerosis_sclerosis_multiple_axonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48547</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>167.447266</td>\n",
       "      <td>Predicted_Test</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.413152</td>\n",
       "      <td>count</td>\n",
       "      <td>-1_patients_study_results_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48548</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>169.941528</td>\n",
       "      <td>Predicted_Test</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.413152</td>\n",
       "      <td>count</td>\n",
       "      <td>-1_patients_study_results_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48549</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>173.979416</td>\n",
       "      <td>Predicted_Test</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.413152</td>\n",
       "      <td>count</td>\n",
       "      <td>-1_patients_study_results_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48550</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>177.606995</td>\n",
       "      <td>Predicted_Test</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.413152</td>\n",
       "      <td>count</td>\n",
       "      <td>-1_patients_study_results_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48551</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>177.454803</td>\n",
       "      <td>Predicted_Test</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.413152</td>\n",
       "      <td>count</td>\n",
       "      <td>-1_patients_study_results_disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48552 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    quantity           value  topic_code       RMSE   \n",
       "0     2011-01-01   81.000000     Actual_Test         117  26.053664  \\\n",
       "1     2012-01-01   18.000000     Actual_Test         117  26.053664   \n",
       "2     2013-01-01    5.000000     Actual_Test         117  26.053664   \n",
       "3     2014-01-01    2.000000     Actual_Test         117  26.053664   \n",
       "4     2015-01-01    0.000000     Actual_Test         117  26.053664   \n",
       "...          ...         ...             ...         ...        ...   \n",
       "48547 2018-01-01  167.447266  Predicted_Test          -1  31.413152   \n",
       "48548 2019-01-01  169.941528  Predicted_Test          -1  31.413152   \n",
       "48549 2020-01-01  173.979416  Predicted_Test          -1  31.413152   \n",
       "48550 2021-01-01  177.606995  Predicted_Test          -1  31.413152   \n",
       "48551 2022-01-01  177.454803  Predicted_Test          -1  31.413152   \n",
       "\n",
       "                         metric   \n",
       "0      influentialCitationCount  \\\n",
       "1      influentialCitationCount   \n",
       "2      influentialCitationCount   \n",
       "3      influentialCitationCount   \n",
       "4      influentialCitationCount   \n",
       "...                         ...   \n",
       "48547                     count   \n",
       "48548                     count   \n",
       "48549                     count   \n",
       "48550                     count   \n",
       "48551                     count   \n",
       "\n",
       "                                             topic_list  \n",
       "0      117_multiple sclerosis_sclerosis_multiple_axonal  \n",
       "1      117_multiple sclerosis_sclerosis_multiple_axonal  \n",
       "2      117_multiple sclerosis_sclerosis_multiple_axonal  \n",
       "3      117_multiple sclerosis_sclerosis_multiple_axonal  \n",
       "4      117_multiple sclerosis_sclerosis_multiple_axonal  \n",
       "...                                                 ...  \n",
       "48547                 -1_patients_study_results_disease  \n",
       "48548                 -1_patients_study_results_disease  \n",
       "48549                 -1_patients_study_results_disease  \n",
       "48550                 -1_patients_study_results_disease  \n",
       "48551                 -1_patients_study_results_disease  \n",
       "\n",
       "[48552 rows x 7 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_for_dataframe = 'forecasted_predicted_actual_Science_1900_2023'\n",
    "cfc.dataframe_to_aws_sql(full_datase,name_for_dataframe)\n",
    "cfc.pull_aws_sql_database(name_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/7: Loading the dataset ...\n"
     ]
    }
   ],
   "source": [
    "working_data = cfc.pull_aws_sql_database(name_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_code</th>\n",
       "      <th>year</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>influentialCitationCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48547</th>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48548</th>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48549</th>\n",
       "      <td>-1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48550</th>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48551</th>\n",
       "      <td>-1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48552 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic_code       year                    metric\n",
       "0             117 2011-01-01  influentialCitationCount\n",
       "1             117 2012-01-01  influentialCitationCount\n",
       "2             117 2013-01-01  influentialCitationCount\n",
       "3             117 2014-01-01  influentialCitationCount\n",
       "4             117 2015-01-01  influentialCitationCount\n",
       "...           ...        ...                       ...\n",
       "48547          -1 2018-01-01                     count\n",
       "48548          -1 2019-01-01                     count\n",
       "48549          -1 2020-01-01                     count\n",
       "48550          -1 2021-01-01                     count\n",
       "48551          -1 2022-01-01                     count\n",
       "\n",
       "[48552 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_data[['topic_code', 'year', 'metric']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
